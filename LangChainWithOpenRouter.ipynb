{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "H5sGwMC8bsYU",
      "metadata": {
        "id": "H5sGwMC8bsYU"
      },
      "source": [
        "Retrieval-augmented generation (RAG)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ho2PQFzeXux1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ho2PQFzeXux1",
        "outputId": "ec2d14f4-2525-4938-e804-854968d857c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m798.0/798.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.3/48.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.1/212.1 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m806.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade --quiet  langchain langchain-openai faiss-cpu tiktoken\n",
        "!pip install youtube-transcript-api  pytube --quiet\n",
        "!pip install python-dotenv --quiet\n",
        "!pip install sentence-transformers --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "3d131b54-ef6c-4216-8047-6a058ef395a1",
      "metadata": {
        "id": "3d131b54-ef6c-4216-8047-6a058ef395a1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import openai\n",
        "# create .env and define OPENAI_API_KEY = API_Token\n",
        "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "NgaH_OaYF_5B",
      "metadata": {
        "id": "NgaH_OaYF_5B"
      },
      "outputs": [],
      "source": [
        "from operator import itemgetter\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "7d77adb9-b482-4698-9edc-229d8d29653c",
      "metadata": {
        "id": "7d77adb9-b482-4698-9edc-229d8d29653c"
      },
      "outputs": [],
      "source": [
        "from langchain.llms import OpenAI\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "model = OpenAI(\n",
        "     base_url=\"https://openrouter.ai/api/v1\",\n",
        "     model=\"gryphe/mythomist-7b\")\n",
        "llm = ChatOpenAI(\n",
        "     base_url=\"https://openrouter.ai/api/v1\",\n",
        "     model=\"gryphe/mythomist-7b\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "1c0745ff-ed89-4fc1-a97d-f1f482fbef22",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1c0745ff-ed89-4fc1-a97d-f1f482fbef22",
        "outputId": "a5deef2e-283b-40b6-fbda-ed2ec7bb958d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'gryphe/mythomist-7b'"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm.model_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "7ZtrxNebIDxa",
      "metadata": {
        "id": "7ZtrxNebIDxa"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import YoutubeLoader,WebBaseLoader\n",
        "\n",
        "# loader = WebBaseLoader(\"https://www.history.com/topics/ancient-rome/ancient-rome\")\n",
        "loader = YoutubeLoader.from_youtube_url(\n",
        "    \"https://www.youtube.com/watch?v=3STDzWv7zLU\", add_video_info=True\n",
        ")\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
        "splits = text_splitter.split_documents(loader.load())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "RSHllHILMUH_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSHllHILMUH_",
        "outputId": "ce7ef529-b002-414a-ed6c-91bb0448bdca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(page_content=\"That's the beauty of a word, isn't it? This is KND featuring. My name is Bick and\\xa0\\nwelcome to the show. Today, we have the pleasure \\nand honor to talk to someone amazing. He's a politician, but not just any politician, a party leader. He's a father and also someone who a lot of\\xa0\\npeople of younger generation look up to and consider him as an idol. And of course,\\n he speaks\\xa0English fluently. Welcome to the show! คุณทิม สวัสดีครับ Thank you for having me. \\nIt's good to\\xa0be here. - Thank you so much\", metadata={'source': '3STDzWv7zLU', 'title': 'คุยภาษาอังกฤษกับ ทิม พิธา ลิ้มเจริญรัตน์ หัวหน้าพรรคก้าวไกล | คำนี้ดี EP.1033', 'description': 'Unknown', 'view_count': 3552351, 'thumbnail_url': 'https://i.ytimg.com/vi/3STDzWv7zLU/hq720.jpg', 'publish_date': '2023-01-25 00:00:00', 'length': 3191, 'author': 'คำนี้ดี (EP.643-ล่าสุด)'})"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "splits[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "1m7YURkTW4IC",
      "metadata": {
        "id": "1m7YURkTW4IC"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import DocArrayInMemorySearch\n",
        "\n",
        "# model replace OpenAI Embedding\n",
        "model_id = 'sentence-transformers/all-MiniLM-L12-v2'\n",
        "# model_id = 'sentence-transformers/all-mpnet-base-v2'\n",
        "\n",
        "model_kwargs = {'device': 'cpu'}\n",
        "hf_embedding = HuggingFaceEmbeddings(\n",
        "    model_name=model_id,\n",
        "    model_kwargs=model_kwargs\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "ouvcQ9KlF6n1",
      "metadata": {
        "id": "ouvcQ9KlF6n1"
      },
      "outputs": [],
      "source": [
        "# Embedding data store in Vector Store\n",
        "vectorstore = FAISS.from_documents(documents=splits, embedding=hf_embedding)\n",
        "retriever = vectorstore.as_retriever(k=10, lambda_mult=0.25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "i2UtPMSb7t_A",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2UtPMSb7t_A",
        "outputId": "52084e76-f9e9-4083-cdc5-bf82716f52d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " The topics mentioned in the video are Youtube video transcript, discussing a world with COVID-19 and geopolitical hot spots, applying new ways of doing things, critical thinking, communication, persistence, exploring examples of good and bad responses, a forum and town hall at a school, JFK School of Government, education system and its changes, student-centric and adult-centric approach, KPIs in education, and leadership styles in the Thai political\n"
          ]
        }
      ],
      "source": [
        "template = \"\"\"Read the following pieces of Youtube video transcript for answering the question at the end.\n",
        "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
        "Please answer in markdown.\n",
        "\n",
        "### context:\n",
        "{context}\n",
        "\n",
        "### question:\n",
        "{question}\n",
        "\n",
        "### answer:\n",
        "\"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "chain2 = (\n",
        "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        ")\n",
        "print(chain2.invoke(\"Please list all topic mentioned in the video.\").content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "sld0jGgtGNYI",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sld0jGgtGNYI",
        "outputId": "1921d60f-15c9-45f4-c508-17b7658cc550"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " The purpose of the video seems to be a conversation or interview in which Tim Phitha Lim-Ecorn, the Head of the Move Forward Party, discusses various topics related to his political journey and experiences, along with his perspectives on government, leadership, and the country's future. This conversation aims to provide insights into his thoughts and motivations, as well as possibly addressing concerns about the party's vision and goals. Additionally, the video likely showcases his public speaking\n"
          ]
        }
      ],
      "source": [
        "\n",
        "template = \"\"\"Answer the question based only on the following context:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Answer in the following language: {language}\n",
        "\"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "chain3 = (\n",
        "    {\n",
        "        \"context\": itemgetter(\"question\") | retriever,\n",
        "        \"question\": itemgetter(\"question\"),\n",
        "        \"language\": itemgetter(\"language\"),\n",
        "    }\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "print(chain3.invoke({\"question\": \"What is purpose of Video\", \"language\": \"english\"}))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
